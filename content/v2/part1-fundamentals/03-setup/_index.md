---
title: Setup & Installation
weight: 3
cascade:
  type: docs
sidebar:
  open: true
---

## Setting Up Your Local LLM Environment

This section guides you through installing and configuring Ollama with its native GUI interface. By the end, you'll have a fully functional local LLM environment ready to use.

### What is Ollama?

**Ollama** is an open-source tool that makes it easy to run large language models locally on your computer. As of 2025, Ollama includes:

- **Native GUI Application**: User-friendly desktop interface
- **Model Library**: One-click access to dozens of open-source models
- **CLI Tools**: Command-line interface for advanced users
- **REST API**: For integration with other applications
- **Cross-Platform**: Works on macOS, Windows, and Linux

### Why Ollama?

Ollama has become the de facto standard for local LLMs because it:

✓ **Simplifies Installation**: One download, everything included
✓ **Manages Models**: Easy downloading, updating, and switching between models
✓ **Optimizes Performance**: Automatically configures for your hardware
✓ **Provides Flexibility**: GUI for beginners, CLI for experts
✓ **Stays Updated**: Regular updates with latest models and features

### What You'll Install

1. **Ollama Application**: The main program with GUI and CLI
2. **Llama 3.2 Model**: Our primary model for the workshop (2-3 GB download)
3. **(Optional) Additional Models**: For experimentation

### System Requirements Recap

Before proceeding, ensure your system meets these requirements:

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| **RAM** | 8 GB | 16 GB |
| **Storage** | 20 GB free | 50 GB free |
| **OS** | macOS 12+, Windows 11, Linux | Latest versions |
| **Internet** | Broadband connection | For initial downloads |

### Setup Process Overview

The setup process has three main steps:

{{< cards >}}
  {{< card link="/v2/part1-fundamentals/03-setup/installation" title="1. Installation" icon="download" subtitle="Download and install Ollama" >}}
  {{< card link="/v2/part1-fundamentals/03-setup/first-chat" title="2. First Chat" icon="chat" subtitle="Download models and start chatting" >}}
  {{< card link="/v2/part1-fundamentals/03-setup/troubleshooting" title="3. Troubleshooting" icon="cog" subtitle="Fix common issues" >}}
{{< /cards >}}

### Estimated Time

- **Installation**: 5-10 minutes
- **Model Download**: 5-15 minutes (depending on internet speed)
- **Testing**: 5 minutes
- **Total**: 15-30 minutes

{{< callout type="info" >}}
**During the Workshop**: We'll walk through each step together. If you've already installed Ollama before the workshop, you're ahead of the game! You can skip to [First Chat](/v2/part1-fundamentals/03-setup/first-chat) to verify everything works.
{{< /callout >}}

### Ready to Start?

Let's begin with [Installation](/v2/part1-fundamentals/03-setup/installation)!
