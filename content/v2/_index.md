---
title: Local LLM Workshop - SWIB 2025
toc: false
---

**A hands-on guide to running large language models on your own hardware**

*SWIB 2025 Edition*

---

## Welcome to the Workshop

Local large language models (LLMs) are continuing to gain traction in 2025 due to their **privacy-first**, **secure**, and **cost-effective** nature. Running LLMs on personal hardware ensures that data remains local (without relying on external servers) and eliminates ongoing subscription or cloud usage fees.

This workshop guides participants through the process of setting up and operating LLMs on their own systems using the latest open-source tools and models.

## Workshop Structure

This is a **4-hour hands-on online workshop** conducted via Zoom, with opportunities to follow along and configure a local LLM environment during the session.

### Part 1: Fundamentals (2 hours)

An introduction to LLM concepts and architecture, including:
- Understanding LLM fundamentals (parameters, tokens, quantization)
- Setting up your local environment with **Ollama GUI**
- Choosing suitable open-source models (Llama 3.2)
- Writing effective instructions (prompts) for the model

### Break (15 minutes)

### Part 2: Intermediate Topics (2 hours)

Advanced techniques and automation:
- Scripting and automating LLM interactions with Python
- Understanding vector embeddings and semantic search
- Building retrieval-augmented generation (RAG) systems
- Integrating external data with local model outputs

## What You'll Learn

By the end of this workshop, you will be able to:

✓ Install and configure Ollama with its native GUI interface
✓ Download and run Llama 3.2 models locally
✓ Write effective prompts for various tasks
✓ Automate LLM interactions using Python
✓ Build semantic search systems with vector embeddings
✓ Implement RAG pipelines to enhance LLM responses with your own data

## Prerequisites

Before the workshop, please ensure you have:

- **Hardware**: Computer with at least 8 GB RAM and 20 GB free storage
- **Operating System**: Windows 11, macOS 12+, or Linux
- **Internet**: Stable connection for downloading models and resources
- **For Part 2**: Python 3.8+ with Jupyter Notebook support

See the [Prerequisites](/v2/prerequisites) page for detailed setup instructions.

## Workshop Materials

All workshop materials, code examples, and Jupyter notebooks are available in the companion repository:

{{< cards >}}
  {{< card link="https://github.com/nishad/llm-workshop-notebooks" title="Workshop Notebooks" icon="document-text" subtitle="Clone the repository for hands-on exercises" >}}
{{< /cards >}}

## Navigation

{{< cards >}}
  {{< card link="/v2/prerequisites" title="Prerequisites" icon="check-circle" subtitle="System requirements and pre-workshop setup" >}}
  {{< card link="/v2/part1-fundamentals" title="Part 1: Fundamentals" icon="academic-cap" subtitle="LLM concepts, setup, and prompting" >}}
  {{< card link="/v2/part2-intermediate" title="Part 2: Intermediate" icon="code" subtitle="Python, embeddings, and RAG" >}}
  {{< card link="/v2/resources" title="Resources" icon="book-open" subtitle="Additional materials and next steps" >}}
{{< /cards >}}

---

## About This Workshop

This workshop is designed for both newcomers and those with prior exposure to LLMs. Whether you're just getting started or looking to deepen your understanding, the hands-on activities will help you build a solid foundation in running and using local LLMs for personal or professional tasks.

The workshop emphasizes **privacy**, **cost-effectiveness**, and **practical skills** that you can apply immediately after the session.
